import asyncio
import sys
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

from langchain_core.messages import HumanMessage
from langchain_core.runnables import RunnableConfig

# Import the graph
from src.open_deep_research.deep_researcher import deep_researcher


async def debug_run():
    """Run the deep researcher with debug capabilities."""

    # í…ŒìŠ¤íŠ¸í•  ì§ˆë¬¸
    question = "GPT-4ì™€ Claude 3.5ì˜ ì£¼ìš” ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    # question = "ì¸ê³µì§€ëŠ¥ ì–¸ì–´ëª¨ë¸ì˜ ì‚¬íšŒì  ì˜í–¥ì— ëŒ€í•´ ë¶„ì„í•´ì¤˜."

    print("=" * 80)
    print("ğŸ”¬ Deep Researcher ë””ë²„ê¹… ëª¨ë“œ")
    print("=" * 80)
    print(f"\nğŸ“ ì§ˆë¬¸: {question}\n")

    # ì´ˆê¸° ë©”ì‹œì§€ êµ¬ì„±
    messages = [HumanMessage(content=question)]

    # ì„¤ì • (ì»¨í”¼ê·œë ˆì´ì…˜)
    config = {
        "model": "gpt-4o",  # ì‚¬ìš©í•  ëª¨ë¸
        "research_model": "gpt-4o",
        "research_model_max_tokens": 16000,
        "stream": False,
        "allow_clarification": False,
        "search_api": "tavily",
        # "enable_vectordb_search": True,
        "max_researcher_iterations":2,
        "max_react_tool_calls":10,
        "max_concurrent_research_units":5
    }

    print("\nğŸš€ ê·¸ë˜í”„ ì‹¤í–‰ ì‹œì‘...\n")
    print("-" * 80)

    try:
        # ì¶”ì í•  ì£¼ìš” ë…¸ë“œ ëª©ë¡
        tracking_nodes = [
            "clarify_with_user",
            "write_research_brief",
            "supervisor_subgraph",
            "lead_researcher_step",
            "scraper_step",
            "planner_step",
            "note_compression",
            "final_report_generation",
        ]

        step_count = 0

        print("\nğŸ“Š ì£¼ìš” ë…¸ë“œ ì‹¤í–‰ ì¶”ì :\n")

        async for event in deep_researcher.astream_events(
            {"messages": messages},
            config=RunnableConfig(configurable=config),
            version="v2",
        ):
            node_name = event.get("name", "")

            # ì¶”ì í•  ë…¸ë“œë§Œ ì¶œë ¥
            if not any(track_node in node_name for track_node in tracking_nodes):
                continue

            # ë…¸ë“œ ì‹œì‘
            if event["event"] == "on_chain_start":
                step_count += 1
                print(f"\n[{step_count}] ğŸ”µ {node_name} ì‹œì‘")
                print("-" * 80)

            # ë…¸ë“œ ì¢…ë£Œ - ì¶œë ¥ ë‚´ìš© í‘œì‹œ
            elif event["event"] == "on_chain_end":
                print(f"âœ… {node_name} ì™„ë£Œ")

                # ì¶œë ¥ ë°ì´í„° í™•ì¸
                if "data" in event and "output" in event["data"]:
                    output = event["data"]["output"]

                    # clarify_with_userì˜ ê²½ìš° ëª…ë ¹ì–´ ì •ë³´ í‘œì‹œ
                    if node_name == "clarify_with_user":
                        if isinstance(output, dict):
                            for key, value in output.items():
                                if key != "messages":
                                    print(f"ğŸ“‹ {key}: {value}")

                    # ë©”ì‹œì§€ ì¶œë ¥
                    if isinstance(output, dict) and "messages" in output:
                        messages_list = output["messages"]
                        print(f"ğŸ“Š ì „ì²´ ë©”ì‹œì§€ ê°œìˆ˜: {len(messages_list)}")

                        # ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì „ì²´ ë‚´ìš© ì¶œë ¥
                        if messages_list:
                            last_msg = messages_list[-1]
                            if hasattr(last_msg, "content") and last_msg.content:
                                content = str(last_msg.content)
                                print("ğŸ“ ìµœì‹  ë©”ì‹œì§€ ì „ì²´ ë‚´ìš©:")
                                print("-" * 40)
                                print(content)
                                print("-" * 40)

                        # ì´ì „ ë©”ì‹œì§€ë„ ê°„ë‹¨íˆ í‘œì‹œ
                        if len(messages_list) > 1:
                            print(f"\nğŸ“š ì´ì „ ë©”ì‹œì§€ë“¤ ({len(messages_list)-1}ê°œ):")
                            for i, msg in enumerate(messages_list[:-1]):
                                if hasattr(msg, "type"):
                                    msg_preview = (
                                        str(msg.content)[:50]
                                        if hasattr(msg, "content") and msg.content
                                        else ""
                                    )
                                    print(f"   [{i+1}] {msg.type}: {msg_preview}...")
                    else:
                        # ë©”ì‹œì§€ê°€ ì•„ë‹Œ ë‹¤ë¥¸ ì¶œë ¥ë„ í‘œì‹œ
                        print(f"ğŸ“¦ ì¶œë ¥ ë°ì´í„°: {output}")

                print("-" * 80)

            # ì—ëŸ¬ ë°œìƒ
            elif event["event"] == "on_chain_error":
                print(f"\nâŒ {node_name} ì—ëŸ¬ ë°œìƒ")
                print("-" * 80)

        # --- ìµœì¢… ê²°ê³¼ ì¶œë ¥ ---
        result = await deep_researcher.ainvoke(
            {"messages": messages},
            config=RunnableConfig(configurable=config),
        )

        print("\n" + "=" * 80)
        print("âœ… ëª¨ë“  ë‹¨ê³„ ì‹¤í–‰ ì™„ë£Œ")
        print("=" * 80)

        if result and "messages" in result:
            final_message = result["messages"][-1]
            print("\nğŸ“„ ìµœì¢… ì‘ë‹µ:")
            print("=" * 80)
            print(final_message.content)
            print("=" * 80)

    except Exception as e:
        print("\n" + "=" * 80)
        print("âŒ ì—ëŸ¬ ë°œìƒ")
        print("=" * 80)
        print(f"\nì—ëŸ¬: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    # ë””ë²„ê¹…ì„ ìœ„í•´ì„œëŠ” asyncio.run() ëŒ€ì‹  asyncio.create_task()ë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤
    asyncio.run(debug_run())
